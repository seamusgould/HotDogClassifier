{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HotDogClassifier.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3sf_IUatIpe"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download dansbecker/hot-dog-not-hot-dog \n",
        "! unzip hot-dog-not-hot-dog.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -q tflite-model-maker\n",
        "!pip uninstall opencv-python-headless \n",
        "!pip install opencv-python-headless==4.1.2.30\n",
        "!pip install tensorflow\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "5btJNYcPP4JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Importing all necessary libraries\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        " \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0"
      ],
      "metadata": {
        "id": "3NH-IOVRvejw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\\"
      ],
      "metadata": {
        "id": "-c29xQUvQe-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "Ez4vJG0uMLtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 128"
      ],
      "metadata": {
        "id": "vMIJKCGzmcmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['hot_dog', 'not_hot_dog']\n",
        "img_size = IMG_SIZE\n",
        "def get_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "cevd9e4svq2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = '/content/train'\n",
        "test = '/content/test'"
      ],
      "metadata": {
        "id": "EBzcfPfvvrdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (IMG_SIZE, IMG_SIZE, 3)"
      ],
      "metadata": {
        "id": "x-NVUtBrGr8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (2, 2), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(16))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "metadata": {
        "id": "lyjyw3JKGrnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        " \n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        " \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        " \n"
      ],
      "metadata": {
        "id": "TWvVwrkiF5ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(entity='<your entity here>', project='SeeFood')\n",
        "\n",
        "# Create a VGG16 model, and removing the last layer that is classifying 1000 images. This will be replaced with images classes we have. \n",
        "vgg = VGG16(input_shape=input_shape, weights='imagenet', include_top=False) #Training with Imagenet weights# Use this line for VGG19 network. Create a VGG19 model, and removing the last layer that is classifying 1000 images. This will be replaced with images classes we have. \n",
        "#vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)# This sets the base that the layers are not trainable. If we'd want to train the layers with custom data, these two lines can be ommitted. \n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = Flatten()(vgg.output) #Output obtained on vgg16 is now flattened. \n",
        "prediction = Dense(2, activation='softmax')(x) # We have 5 classes, and so, the prediction is being done on len(folders) - 5 classes#Creating model object \n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
        "\n",
        "history = model.fit(train_generator, validation_data=validation_generator, epochs=50, batch_size=16, \n",
        "          callbacks=[WandbCallback(data_type=\"image\", validation_data=validation_generator), \n",
        "                     tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "hpf4RHQFB7ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.post_training_quantize=True\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "f_w36wPiHXYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_convert --graph_def_file=optimized_graph.pb \\\n",
        "  --output_file=output/optimized_graph_quantized.tflite \\\n",
        "  --output_format=TFLITE \\\n",
        "  --input_shape=1,299,299,3 \\\n",
        "  --input_array=Mul \\\n",
        "  --output_array=final_result \\\n",
        "  --inference_type=QUANTIZED_UINT8 \\\n",
        "  --std_dev_values=128 --mean_values=128 \\\n",
        "  --default_ranges_min=-6 --default_ranges_max=6 \\\n",
        "  --quantize_weights=true\n"
      ],
      "metadata": {
        "id": "bLSsbEeb5N9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MSJVxH77uXvg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}